### Phase-1: LLM Foundations
This repository documents my Phase-1 learning focused on LLMs, Python for APIs, and cloud fundamentals.
The goal is to build execution-level understanding through hands-on practice, not just theory.
### Why this repository
I am building this repository to develop real-world skills in:
Working with LLM APIs
Writing clean and readable Python code
Using Git and GitHub in a professional workflow
## What this repository includes
Python environment setup
Git & GitHub workflow
Small Python scripts and experiments (in progress)
###  Current Status
# Week-1: LLM Foundations: 
# What does this project do?
- This project contains a Python script that:
- Sends a prompt to an AI model
- Receives and prints the response
- Saves the prompt and response into a file (llm_inference_data)
# What I learned this week
- JSON is simpler than I initially thought
- How to use Python to call an LLM API using an API key
- Basic understanding of tokens and API cost 
- Fundamentals of prompt engineering
#  What was confusing this week
- Choosing between different types of LLM models
- Creating and saving data into files correctly
- These points will be improved in the next phase.
## week - 2 - Chatbot:
# What I Learned This week?
- Prompt Engineering Basics
- Chat loop logic
- Memory Handling
- Logging Conversations
- Cost Handling 
# Limitations:
- It only remembers previous prompt by user.
- Only Addded three different Prompts
- It always ask the question of selecting system Prompt
- CLI only
- NO UI Yet 
